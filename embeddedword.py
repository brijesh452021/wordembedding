# -*- coding: utf-8 -*-
"""embeddedword

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R4W9gW_Hp4niBAM41qx9gb7TsrOHBpcb
"""

from tensorflow.keras.preprocessing.text import one_hot
from tensorflow.keras.layers import Embedding
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential

import tensorflow as tf
print(tf.__version__)

sentence=['She did a happy dance because all of the socks from the dryer matched.',
'He found the chocolate covered roaches quite tasty.',
'She was not sure whether to be impressed or concerned that he folded underwear in neat little packages.',
'It is not possible to convince a monkey to give you a banana by promising it infinite bananas when they die.',
'It would have been a better night if the guys next to us were not in the splash zone.',
'Nobody has encountered an explosive daisy and lived to tell the tale.',
'Mothers spend months of their lives waiting on their children.',
'Nothing seemed out of place except the washing machine in the bar.',
'I caught my squirrel rustling through my gym bag.',
'She was the type of girl who wanted to live in a pink house.',]

sentence

vocab_size=10000

one_hotrepr=[one_hot(words,vocab_size) for words in sentence]
print(one_hotrepr)

Fixed_length=25
output_dimesnsion=10

embedded_document=pad_sequences(one_hotrepr, maxlen=Fixed_length, padding='pre')
print(embedded_document)

Model=Sequential()
Model.add(Embedding(vocab_size,output_dimesnsion,input_length=Fixed_length))
Model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])

Model.summary()

print(Model.predict(embedded_document))